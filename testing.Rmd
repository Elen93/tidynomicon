---
title: "Testing"
output:
  html_document:
    css: "languages.css"
---

Mistakes were made in [the previous tutorial](cleanup.Rmd).
It would be hubris to believe that we will not make more as we continue to clean this data.
What will guide us safely through these dark caverns and back into the light of day?

The answer is testing.
We must test our assumptions, test our code, test our very *being* if we are to advance.
Luckily for us,
R provides tools for this purpose not unlike those available in Python.

## The Problem

We have been given several more CSV files to clean up.
The first,
`raw/at_health_facilities.csv`,
shows the percentage of births at health facilities by country, year, and mother's age.
It comes from the same UNICEF website as our previous data,
but has a different set of problems.
Here are its first few lines:

```
,,GLOBAL DATABASES,,,,,,,,,,,,,
,,[data.unicef.org],,,,,,,,,,,,,
,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,
Indicator:,Delivered in health facilities,,,,,,,,,,,,,,
Unit:,Percentage,,,,,,,,,,,,,,
,,,,Mother's age,,,,,,,,,,,
iso3,Country/areas,year,Total ,age 15-17,age 18-19,age less than 20,age more than 20,age 20-34,age 35-49,Source,Source year,,,,
AFG,Afghanistan,2010, 	33 , 	25 , 	29 , 	28 , 	31 , 	31 , 	31 ,MICS,2010,,,,
ALB,Albania,2005, 	98 , 	100 , 	96 , 	97 , 	98 , 	99 , 	92 ,MICS,2005,,,,
ALB,Albania,2008, 	98 , 	94 , 	98 , 	97 , 	98 , 	98 , 	99 ,DHS,2008,,,,
...
```

and its last:

```
ZWE,Zimbabwe,2005, 	66 , 	64 , 	64 , 	64 , 	67 , 	69 , 	53 ,DHS,2005,,,,
ZWE,Zimbabwe,2009, 	58 , 	49 , 	59 , 	55 , 	59 , 	60 , 	52 ,MICS,2009,,,,
ZWE,Zimbabwe,2010, 	64 , 	56 , 	66 , 	62 , 	64 , 	65 , 	60 ,DHS,2010,,,,
ZWE,Zimbabwe,2014, 	80 , 	82 , 	82 , 	82 , 	79 , 	80 , 	77 ,MICS,2014,,,,
,,,,,,,,,,,,,,,
Definition:,Percentage of births delivered in a health facility.,,,,,,,,,,,,,,
,"The indicator refers to women who had a live birth in a recent time period, generally two years for MICS and five years for DHS.",,,,,,,,,,,,,,
,,,,,,,,,,,,,,,
Note:,"Database include reanalyzed data from DHS and MICS, using a reference period of two years before the survey.",,,,,,,,,,,,,,
,Includes surveys which microdata were available as of April 2016. ,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,
Source:,"UNICEF global databases 2016 based on DHS, MICS .",,,,,,,,,,,,,,
,,,,,,,,,,,,,,,
Contact us:,data@unicef.org,,,,,,,,,,,,,,
```

There are three files in this collection,
all exported from the same Excel spreadsheet.
Rather than writing a separate script for each,
we should create a tool that will handle them all.
At first glance,
the problems we need to solve to do this are:

1.  Each file may contain a different number of records,
    so our tool should select rows by content rather than by absolute row number.
2.  Each file may contain a different set of columns,
    so our tool should select those that always appear by name
    and somehow infer the location of the rest.

These two requirements will make our program significantly more complicated,
so we should tackle each with its own testable function.

## The Tools at Hand

The standard testing library for R is called [testthat](https://github.com/r-lib/testthat).
Like Python's [unittest](https://docs.python.org/3/library/unittest.html) library,
it is a member of the [xUnit](https://en.wikipedia.org/wiki/XUnit) family of testing libraries:

1.  Each test consists of a single function that tests a single property or behavior of the system.
2.  Tests are collected into files with prescribed names that can be found by a *test runner*.
3.  Shared setup and teardown operations are put in functions of their own.

To explore its operation,
let's create a file called `scripts/find_empty_01.R`
that defines a single function `find_empty_rows` that identifies all the empty rows in a CSV file.
Our first implementation is:

```{r code=readLines("scripts/find_empty_01.R")}
```

This is complex enough to merit line-by-line exegesis:

1.  Define the function with one argument `source`, from which we shall read.
2.  Read tabular data from that source and assign the resulting tibble to `data`.
3.  Begin a pipeline that will assign something to the variable `empty`.
    1.  Use `pmap` to map a function across each row of the tibble.
        Since we don't know how many columns are in each row,
        we use `...` to take any number of arguments.
    2.  Convert the variable number of arguments to a list.
    3.  Check to see if all of those arguments are either `NA` or the empty string.
    4.  Close the mapped function's definition.
4.  Start another pipeline.
    This one's result isn't assigned to a variable,
    so whatever it produces will be the value returned by `find_empty_rows`.
    1.  Construct a tibble that contains only the row numbers of the original table in a column called `id`.
    2.  Filter those row numbers to keep only those corresponding to rows that were entirely empty.
        The `as.logical` call inside `filter` is needed because the value returned by `pmap`
        (which we stored in `empty`)
        is a list, not a logical vector.
    3.  Use `pull` to get the one column we want from the filtered tibble as a vector.

There is a lot going on here,
particularly if you are (as I am at the time of writing)
new to R.
But now that we have it,
we can do this:

```{r}
library(tidyverse)
source("scripts/find_empty_01.R")
find_empty_rows("a,b\n1,2\n,\n5,6")
```

The `source` function reads R code from the given source.
Using this inside an RMarkdown file is usually a bad idea,
since the generated HTML or PDF won't show readers what code we loaded and ran.
On the other hand,
if we are creating command-line tools for use on clusters or in other batch processing modes,
and are careful to display the code in a nearby block,
the stain on our soul is excusable.

The more interesting part of this example is the call to `find_empty_rows`.
Instead of giving it the name of a file,
we have given it the text of the CSV we want parsed.
This is then passed to `read_csv`,
which (according to documentation that only took us 15 minutes to realize we had already seen)
interprets its first argument as *either* a filename *or* the actual text to be parsed
depending on whether it contains a newline character.
This allows us to write code like this:

```{r}
inputs <- list("a\n1", "a,b\n1,2", "a,b\n,", "a,b\n1,2\n,\n5,6")
outputs <- list(c(), c(), c(1), c(2))
map2(inputs, outputs, function(x, y) find_empty_rows(x) == y)
```

Hm.
On the one hand, nothing crashed.
On the other hand,
the comparison inside `map2` is sometimes producing `TRUE` and sometimes producingâ€¦
an empty logical vector?
Let's have a closer look:

```{r}
print("find_empty_rows with a single non-empty row")
find_empty_rows("a\n1")
print("an empty column")
c()
print("is integer(0) equal to NULL")
integer(0) == NULL
print("any(logical(0))")
any(logical(0))
print("all(logical(0))")
all(logical(0))
```

The fact that `any` of an empty logical vector is `FALSE` may not be surprising,
but `all` of an empty vector being `TRUE` is unexpected.
It's tempting to explore the reasons,
but we must resist.
Our chosen mission is to test this function,
and luckily for us,
the next tool we will use has already grappled with the question of truth.
