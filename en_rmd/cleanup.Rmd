---
title: "Cleaning Up Data"
output: md_document
questions:
  - "How do I read tabular data into a program?"
  - "How do I control the way missing values are handled while I'm reading data?"
  - "What functions should I use to tidy up messy data?"
  - "How can I combine partial tables into a single large table?"
objectives:
  - "Describe and use the `read_csv` function."
  - "Describe and use the `str_replace` function."
  - "Describe and use the `is.numeric` and `as.numeric` functions."
  - "Describe and use the `map` function and its kin."
  - "Describe and use pre-allocation to capture the results of loops."
keypoints:
  - "Develop data-cleaning scripts one step at a time, checking intermediate results carefully."
  - "Use `read_csv` to read CSV-formatted tabular data into a tibble."
  - "Use the `skip` and `na` parameters of `read_csv` to skip rows and interpret certain values as `NA`."
  - "Use `str_replace` to replace portions of strings that match patterns with new strings."
  - "Use `is.numeric` to test if a value is a number and `as.numeric` to convert it to a number."
  - "Use `map` to apply a function to every element of a vector in turn."
  - "Use `map_dfc` and `map_dfr` to map functions across the columns and rows of a tibble."
  - "Pre-allocate storage in a list for each result from a loop and fill it in rather than repeatedly extending the list."
---

```{r setup, include=FALSE}
source("common.R")
library(tidyverse)
```

Here is a sample of data from `raw/infant_hiv.csv`,
where `...` shows values elided to make the segment readable:

```text
"Early Infant Diagnosis: Percentage of infants born to women living with HIV...",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2009,,,2010,,,2011,,,2012,,,2013,,,2014,,,2015,,,2016,,,2017,,,
ISO3,Countries,Estimate,hi,lo,Estimate,hi,lo,Estimate,hi,lo,Estimate,hi,lo,...
AFG,Afghanistan,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,
ALB,Albania,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,
DZA,Algeria,-,-,-,-,-,-,38%,42%,35%,23%,25%,21%,55%,60%,50%,27%,30%,25%,23%,25%,21%,33%,37%,31%,61%,68%,57%,
AGO,Angola,-,-,-,3%,4%,2%,5%,7%,4%,6%,8%,5%,15%,20%,12%,10%,14%,8%,6%,8%,5%,1%,2%,1%,1%,2%,1%,
... many more rows ...
YEM,Yemen,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,
ZMB,Zambia,59%,70%,53%,27%,32%,24%,70%,84%,63%,74%,88%,67%,64%,76%,57%,91%,>95%,81%,43%,52%,39%,43%,51%,39%,46%,54%,41%,
ZWE,Zimbabwe,-,-,-,12%,15%,10%,23%,28%,20%,38%,47%,33%,57%,70%,49%,54%,67%,47%,59%,73%,51%,71%,88%,62%,65%,81%,57%,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,2009,,,2010,,,2011,,,2012,,,2013,,,2014,,,2015,,,2016,,,2017,,,
,,Estimate,hi,lo,Estimate,hi,lo,Estimate,hi,lo,Estimate,hi,lo,...
Region,East Asia and the Pacific,25%,30%,22%,35%,42%,29%,30%,37%,26%,32%,38%,27%,28%,34%,24%,26%,31%,22%,31%,37%,27%,30%,35%,25%,28%,33%,24%,
,Eastern and Southern Africa,23%,29%,20%,44%,57%,37%,48%,62%,40%,54%,69%,46%,51%,65%,43%,62%,80%,53%,62%,79%,52%,54%,68%,45%,62%,80%,53%,
,Eastern Europe and Central Asia,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,-,
... several more rows ...
,Sub-Saharan Africa,16%,22%,13%,34%,46%,28%,37%,50%,30%,43%,57%,35%,41%,54%,33%,50%,66%,41%,50%,66%,41%,45%,60%,37%,52%,69%,42%,
,Global,17%,23%,13%,33%,45%,27%,36%,49%,29%,41%,55%,34%,40%,53%,32%,48%,64%,39%,49%,64%,40%,44%,59%,36%,51%,67%,41%,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Indicator definition: Percentage of infants born to women living with HIV... ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Note: Data are not available if country did not submit data...,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Data source: Global AIDS Monitoring 2018 and UNAIDS 2018 estimates,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"For more information on this indicator, please visit the guidance:...",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"For more information on the data, visit data.unicef.org",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
```

This is a mess---no, more than that, it is an affront to decency.
There are comments mixed with data,
values' actual indices have to be synthesized by combining column headings from two rows
(two thirds of which have to be carried forward from previous columns),
and so on.
We want to create the tidy data found in `tidy/infant_hiv.csv`:

```text
country,year,estimate,hi,lo
AFG,2009,NA,NA,NA
AFG,2010,NA,NA,NA
AFG,2011,NA,NA,NA
AFG,2012,NA,NA,NA
...
ZWE,2016,0.71,0.88,0.62
ZWE,2017,0.65,0.81,0.57
```

To bring this data to a state of grace will take some trial and effort,
which we shall do in stages.

## How do I inspect the raw data?

We will begin by reading the data into a tibble:

```{r}
raw <- read_csv("raw/infant_hiv.csv")
head(raw)
```

All right:
R isn't able to infer column names,
so it uses the entire first comment string as a very long column name
and then makes up names for the other columns.
Looking at the file,
the second row has years (spaced at three-column intervals)
and the column after that has the [ISO3 country code](#g:iso3-country-code),
the country's name,
and then "Estimate", "hi", and "lo" repeated for every year.
We are going to have to combine what's in the second and third rows,
so we're going to have to do some work no matter which we skip or keep.
Since we want the ISO3 code and the country name,
let's skip the first two rows.

```{r}
raw <- read_csv("raw/infant_hiv.csv", skip = 2)
head(raw)
```

That's a bit of an improvement,
but why are all the columns `character` instead of numbers?
This happens because:

1.  our CSV file uses `-` (a single dash) to show missing data, and
2.  all of our numbers end with `%`, which means those values actually *are* character strings.

We will tackle the first problem by setting `na = c("-")` in our `read_csv` call
(since we should never do ourselves what a library function will do for us):

```{r}
raw <- read_csv("raw/infant_hiv.csv", skip = 2, na = c("-"))
head(raw)
```

That's progress.
We now need to strip the percentage signs and convert what's left to numeric values.
To simplify our lives,
let's get the `ISO3` and `Countries` columns out of the way.
We will save the ISO3 values for later use
(and because it will illustrate a point about data hygiene that we want to make later,
but which we don't want to reveal just yet).

```{r error=TRUE}
raw <- read_csv("raw/infant_hiv.csv", skip = 2, na = c("-"))
countries <- raw$ISO3
body <- raw %>%
  filter(-ISO3, -Countries)
```

In the Hollywood version of this lesson,
we would sigh heavily at this point as we realize that we should have called `select`, not `filter`.
Once we make that change,
we can move forward once again:

```{r}
raw <- read_csv("raw/infant_hiv.csv", skip = 2, na = c("-"))
countries <- raw$ISO3
body <- raw %>%
  select(-ISO3, -Countries)
head(body)
```

But wait.
Weren't there some aggregate lines of data at the end of our input?
What happened to them?

```{r}
tail(countries, n = 25)
```

Once again the actor playing our part on screen sighs heavily.
How are we to trim this?
Since there is only one file,
we can manually count the number of rows we are interested in
(or rather, open the file with an editor or spreadsheet program, scroll down, and check the line number),
and then slice there.
This is a very bad idea if we're planning to use this script on other files---we should
instead look for the first blank line or the entry for Zimbabwe or something like that---but
let's revisit the problem once we have our data in place.

```{r}
num_rows <- 192
raw <- read_csv("raw/infant_hiv.csv", skip = 2, na = c("-"))
sliced <- slice(raw, 1:num_rows)
countries <- sliced$ISO3
tail(countries, n = 5)
```

Notice that we're counting rows *not including* the two we're skipping,
which means that the 192 in the call to `slice` above corresponds to row 195 of our original data:
195, not 194, because we're using the first row of unskipped data as headers and yes,
you are in fact making a faint whimpering sound.
We promise we will revisit the problem of slicing data without counting rows manually
so as to reduce the frequency with which that sound is heard.

And notice also that we are slicing, *then* extracting the column containing the countries.
We did, in a temporary version of this script,
peel off the countries, slice those, and then wonder why our main data table still had unwanted data at the end.
Vigilance, my friends---vigilance shall be our watchword,
and in light of that,
we shall first test our plan for converting our strings to numbers:

```{r}
fixture <- c(NA, "1%", "10%", "100%")
result <- as.numeric(str_replace(fixture, "%", "")) / 100
result
```

And as a further check:

```{r}
is.numeric(result)
```

The function `is.numeric` is `TRUE` for both `NA` and actual numbers,
so it is doing the right thing here,
and so are we.
Our updated conversion script is now:

```{r}
raw <- read_csv("raw/infant_hiv.csv", skip = 2, na = c("-"))
sliced <- slice(raw, 1:192)
countries <- sliced$ISO3
body <- raw %>%
  select(-ISO3, -Countries)
numbers <- as.numeric(str_replace(body, "%", "")) / 100
is.numeric(numbers)
```

Oh dear.
It appears that some function `str_replace` is calling is expecting an atomic vector,
not a tibble.
It worked for our test case because that was a character vector,
but tibbles have more structure than that.

The second complaint is that `NA`s were introduced,
which is troubling because we didn't get a complaint when we had actual `NA`s in our data.
However,
`is.numeric` tells us that all of our results are numbers.
Let's take a closer look:

```{r}
is.tibble(body)
```
```{r}
is.tibble(numbers)
```

Perdition.
After browsing the data,
we realize that some entries are `">95%"`,
i.e.,
there is a greater-than sign as well as a percentage in the text.
We will need to regularize those before we do any conversions.

Before that,
however,
let's see if we can get rid of the percent signs.
The obvious way is is to use `str_replace(body, "%", "")`,
but that doesn't work:
`str_replace` works on vectors,
but a tibble is a list of vectors.
Instead,
we can use a [higher-order function](#g:higher-order-function) called `map`
to apply the function `str_replace` to each column in turn to get rid of the percent signs:

```{r}
raw <- read_csv("raw/infant_hiv.csv", skip = 2, na = c("-"))
sliced <- slice(raw, 1:192)
countries <- sliced$ISO3
body <- raw %>%
  select(-ISO3, -Countries)
trimmed <- map(body, str_replace, pattern = "%", replacement = "")
head(trimmed)
```

Perdition once again.
The problem now is that `map` produces a raw list as output.
The function we want is `map_dfr`,
which maps a function across the rows of a tibble and returns a tibble as a result.
(There is a corresponding function `map_dfc` that maps a function across columns.)

```{r}
raw <- read_csv("raw/infant_hiv.csv", skip = 2, na = c("-"))
sliced <- slice(raw, 1:192)
countries <- sliced$ISO3
body <- raw %>%
  select(-ISO3, -Countries)
trimmed <- map_dfr(body, str_replace, pattern = "%", replacement = "")
head(trimmed)
```

Now to tackle those `">95%"` values.
It turns out that `str_replace` uses regular expressions,
not just direct string matches,
so we can get rid of the `>` at the same time as we get rid of the `%`.
We will check by looking at the first `Estimate` column,
which earlier inspection informed us had at least one `">95%"` in it:

```{r}
raw <- read_csv("raw/infant_hiv.csv", skip = 2, na = c("-"))
sliced <- slice(raw, 1:192)
countries <- sliced$ISO3
body <- raw %>%
  select(-ISO3, -Countries)
trimmed <- map_dfr(body, str_replace, pattern = ">?(\\d+)%", replacement = "\\1")
trimmed$Estimate
```

Excellent.
We can now use `map_dfr` to convert the columns to numeric percentages
using an anonymous function that we define inside the `map_dfr` call itself:

```{r}
raw <- read_csv("raw/infant_hiv.csv", skip = 2, na = c("-"))
sliced <- slice(raw, 1:192)
countries <- sliced$ISO3
body <- raw %>%
  select(-ISO3, -Countries)
trimmed <- map_dfr(body, str_replace, pattern = ">?(\\d+)%", replacement = "\\1")
percents <- map_dfr(trimmed, function(col) as.numeric(col) / 100)
head(percents)
```

27 warnings is rather a lot,
so let's see what running `warnings()` produces right after the `as.numeric` call:

```{r}
raw <- read_csv("raw/infant_hiv.csv", skip = 2, na = c("-"))
sliced <- slice(raw, 1:192)
countries <- sliced$ISO3
body <- raw %>%
  select(-ISO3, -Countries)
trimmed <- map_dfr(body, str_replace, pattern = ">?(\\d+)%", replacement = "\\1")
percents <- map_dfr(trimmed, function(col) as.numeric(col) / 100)
warnings()
```

Something is still not right.
The first `Estimates` column looks all right,
so let's have a look at the second column:

```{r}
trimmed$hi
```

Empty strings.
Why'd it have to be empty strings?
More importantly,
where are they coming from?
Let's backtrack by displaying the `hi` column of each of our intermediate variables...

...and there's our bug.
We are creating a variable called `sliced` that has only the rows we care about,
but then using the full table in `raw` to create `body`.
It's a simple mistake,
and one that could easily have slipped by us.
Here is our revised script,
in which we check *both* the head and the tail:

```{r}
raw <- read_csv("raw/infant_hiv.csv", skip = 2, na = c("-"))
sliced <- slice(raw, 1:192)
countries <- sliced$ISO3
body <- sliced %>%
  select(-ISO3, -Countries)
trimmed <- map_dfr(body, str_replace, pattern = ">?(\\d+)%", replacement = "\\1")
percents <- map_dfr(trimmed, function(col) as.numeric(col) / 100)
head(percents)
```
```{r}
tail(percents)
```

Comparing this to the raw data file convinces us that yes,
we are now converting the percentages properly,
which means we are halfway home.

## How do I tidy the data?

We now have numeric values in `percents` and corresponding ISO3 codes in `countries`.
What we do *not* have is tidy data:
countries are not associated with records,
years are not recorded at all,
and the column headers for `percents` have mostly been manufactured for us by R.
We must now sew these parts together like Dr. Frankenstein's trusty assistant Igor
(who, like all in his trade, did most of the actual work but was given only crumbs of credit).

Our starting point is this:

1.  Each row in `percents` corresponds positionally to an ISO3 code in `countries`.
2.  Each group of three consecutive columns in `percents` has the estimate, high, and low values
    for a single year.
3.  The years themselves are not stored in `percents`,
    but we know from inspection that they start at 2009 and run without interruption to 2017.

Our strategy is to make a list of temporary tables:

1.  Take three columns at a time from `percents` to create a temporary tibble.
2.  Join `countries` to it.
3.  Create a column holding the year in each row and join that as well.

and then join those temporary tables row-wise to create our final tidy table.
(We might,
through clever use of `scatter` and `gather`,
be able to do this without a loop,
but at this point on our journey,
a loop is probably simpler.)
Here is the addition to our script:

```{r}
first_year <- 2009
last_year <- 2017
num_years <- (last_year - first_year) + 1
chunks <- vector("list", num_years)
for (year in 1:num_years) {
  end <- year + 2
  temp <- select(percents, year:end)
  names(temp) <- c("estimate", "hi", "lo")
  temp$country <- countries
  temp$year <- rep((first_year + year) - 1, num_rows)
  temp <- select(temp, country, year, everything())
  chunks[[year]] <- temp
}
chunks
```

We start by giving names to our years;
if or when we decide to use this script for other data files,
we should extract the years from the data itself.
We then use `vector` to create the storage we are going to need to hold our temporary tables.
We could grow the list one item at a time,
but [allocating storage in advance](#g:storage-allocation) is more efficient
and serves as a check on our logic:
if our loop doesn't run for the right number of iterations,
we will either overflow our list or have empty entries,
either of which should draw our attention.

Within the loop we figure out the bounds on the next three-column stripe,
select that,
and then give those three columns meaningful names.
This ensures that when we join all the sub-tables together,
the columns of the result will also be sensibly named.
Attaching the ISO3 country codes is as easy as assigning to `temp$country`,
and replicating the year for each row is easily done using the `rep` function.
We then reorder the columns to put country and year first
(the call to `everything` inside `select` selects all columns that aren't specifically selected),
and then we assign the temporary table to the appropriate slot in `chunks` using `[[..]]`.

As its name suggests,
`bind_rows` takes a list of tables and concatenates their rows in order.
Since we have taken care to give all of those tables the same column names,
no subsequent renaming is necessary.
We do,
however,
use `arrange` to order entries by country and year.

Now comes the payoff for all that hard work:

```{r}
tidy <- bind_rows(chunks)
tidy <- arrange(tidy, country, year)
tidy
```

What fresh hell is this?
Why do some rows have empty strings where country codes should be
and `NA`s for the three percentages?
Is our indexing off?
Have we somehow created one extra row for each year with nonsense values?

No.
It is not our tools that have failed us, or our reason, but our data.
("These parts are not fresh, Igor---I must have *fresh* parts to work with!")
Let us do this:

```{r}
raw <- read_csv("raw/infant_hiv.csv", skip = 2, na = c("-"))
missing <- raw %>%
  filter(is.na(Countries) | (Countries == "") | is.na(ISO3) | (ISO3 == "")) %>%
  select(Countries, ISO3)
missing
```

The lack of ISO3 country code for the region names doesn't bother us,
but Kosovo is definitely a problem.
[According to Wikipedia][wikipedia-iso3],
UNK is used for Kosovo residents whose travel documents were issued by the United Nations,
so we will fill that in with an ugly hack immediately after loading the data:

```{r}
raw <- read_csv("raw/infant_hiv.csv", skip = 2, na = c("-"))
raw$ISO3[raw$Countries == "Kosovo"] <- "UNK"
missing <- raw %>%
  filter(is.na(Countries) | (Countries == "") | is.na(ISO3) | (ISO3 == "")) %>%
  select(Countries, ISO3)
missing
```

All right.
Let's add that hack to our script,
then save the result to a file.
The whole thing is now 38 lines long:

```{r}
# Constants.
raw_filename <- "raw/infant_hiv.csv"
tidy_filename <- "tidy/infant_hiv.csv"
num_rows <- 192
first_year <- 2009
last_year <- 2017

# Get and clean percentages.
raw <- read_csv(raw_filename, skip = 2, na = c("-"))
raw$ISO3[raw$Countries == "Kosovo"] <- "UNK"
sliced <- slice(raw, 1:num_rows)
countries <- sliced$ISO3
body <- sliced %>%
  select(-ISO3, -Countries)
trimmed <- map_dfr(body, str_replace, pattern = ">?(\\d+)%", replacement = "\\1")
percents <- map_dfr(trimmed, function(col) as.numeric(col) / 100)

# Separate three-column chunks and add countries and years.
num_years <- (last_year - first_year) + 1
chunks <- vector("list", num_years)
for (year in 1:num_years) {
  end <- year + 2
  temp <- select(percents, year:end)
  names(temp) <- c("estimate", "hi", "lo")
  temp$country <- countries
  temp$year <- rep((first_year + year) - 1, num_rows)
  temp <- select(temp, country, year, everything())
  chunks[[year]] <- temp
}

# Combine chunks and order by country and year.
tidy <- bind_rows(chunks)
tidy <- arrange(tidy, country, year)

# Save.
write_csv(tidy, tidy_filename)
```

"It's alive!",
we exclaim,
but we can do better.
Let's start by using a pipeline for the code that extracts and formats the percentages:

```{r}
# Constants...

# Get and clean percentages.
raw <- read_csv(raw_filename, skip = 2, na = c("-"))
raw$ISO3[raw$Countries == "Kosovo"] <- "UNK"
sliced <- slice(raw, 1:num_rows)
countries <- sliced$ISO3
percents <- sliced %>%
  select(-ISO3, -Countries) %>%
  map_dfr(str_replace, pattern = ">?(\\d+)%", replacement = "\\1") %>%
  map_dfr(function(col) as.numeric(col) / 100)

# Separate three-column chunks and add countries and years...

# Combine chunks and order by country and year...

# Check...
```

The two changes are:

1.  We use a `%>%` pipe for the various transformations involved in creating percentages.
2.  We write the result to `temp.csv` so that we can compare it to the file created by our previous script.
    We should always do this sort of comparison when refactoring code in ways that isn't meant to change output;
    if the file is small enough to store in version control,
    we could overwrite it and use `git diff` or something similar to check whether it has changed.
    However,
    we would then have to trust ourselves to be careful enough not to accidentally commit changes,
    and frankly,
    we are no longer sure how trustworthy we are...

After checking that this has not changed the output,
we pipeline the computation in the loop:

```{r}
# Constans...

# Get and clean percentages...

# Separate three-column chunks and add countries and years.
num_years <- (last_year - first_year) + 1
chunks <- vector("list", num_years)
for (year in 1:num_years) {
  chunks[[year]] <- select(percents, year:(year + 2)) %>%
    rename(estimate = 1, hi = 2, lo = 3) %>%
    mutate(country = countries,
           year = rep((first_year + year) - 1, num_rows)) %>%
    select(country, year, everything())
}

# Combine chunks and order by country and year.
tidy <- bind_rows(chunks) %>%
  arrange(country, year)
```

We have introduced a call to `rename` here to give the columns of each sub-table the right names,
and used `mutate` instead of assigning to named columns one by one.
The lack of intermediate variables may make the code harder to debug using print statements,
but certainly makes this incantation easier to read aloud.

So we run it and inspect the output and it's the same as what we had
and we're about to commit to version control
when we decide to double check against the original data and guess what?
The values for Argentina are wrong.
In fact,
the values for most countries and years are wrong:
only the ones in the first three columns are right.
The problem,
it turns out,
is that our loop index `year` is going up in ones,
while each year's data is three columns wide.
Here's the final, *final*, __*final*__ version:

```{r}
library(tidyverse)

# Constants.
raw_filename <- "raw/infant_hiv.csv"
tidy_filename <- "tidy/infant_hiv.csv"
first_year <- 2009
last_year <- 2017
num_rows <- 192

# Get and clean percentages.
raw <- read_csv(raw_filename, skip = 2, na = c("-"))
raw$ISO3[raw$Countries == "Kosovo"] <- "UNK"
sliced <- slice(raw, 1:num_rows)
countries <- sliced$ISO3
percents <- sliced %>%
  select(-ISO3, -Countries) %>%
  map_dfr(str_replace, pattern = ">?(\\d+)%", replacement = "\\1") %>%
  map_dfr(function(col) as.numeric(col) / 100)

# Separate three-column chunks and add countries and years.
num_years <- (last_year - first_year) + 1
chunks <- vector("list", num_years)
for (year in 1:num_years) {
  start = 3 * (year - 1) + 1
  chunks[[year]] <- select(percents, start:(start + 2)) %>%
    rename(estimate = 1, hi = 2, lo = 3) %>%
    mutate(country = countries,
           year = rep((first_year + year) - 1, num_rows)) %>%
    select(country, year, everything())
}

# Combine chunks and order by country and year.
tidy <- bind_rows(chunks) %>%
  arrange(country, year)

# Check.
write_csv(tidy, tidy_filename)
```

We're done,
and we have learned a lot of R,
but what we have also learned is that we make mistakes,
and that those mistakes can easily slip past us.
If people are going to use our cleaned-up data in their analyses,
we need a better way to develop and check our scripts.

{% include links.md %}
